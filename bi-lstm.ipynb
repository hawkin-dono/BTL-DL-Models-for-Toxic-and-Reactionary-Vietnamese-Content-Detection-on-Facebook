{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10134965,"sourceType":"datasetVersion","datasetId":6254878}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-09T16:34:15.311736Z","iopub.execute_input":"2024-12-09T16:34:15.312242Z","iopub.status.idle":"2024-12-09T16:34:16.338951Z","shell.execute_reply.started":"2024-12-09T16:34:15.312185Z","shell.execute_reply":"2024-12-09T16:34:16.337964Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/sentiments/val.csv\n/kaggle/input/sentiments/train.csv\n/kaggle/input/sentiments/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.nn import functional as F\nfrom collections import Counter\nfrom nltk.tokenize import word_tokenize","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T16:34:16.340964Z","iopub.execute_input":"2024-12-09T16:34:16.341494Z","iopub.status.idle":"2024-12-09T16:34:20.399090Z","shell.execute_reply.started":"2024-12-09T16:34:16.341445Z","shell.execute_reply":"2024-12-09T16:34:20.398279Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/sentiments/train.csv')\nval_df = pd.read_csv('/kaggle/input/sentiments/val.csv')\ntest_df = pd.read_csv('/kaggle/input/sentiments/test.csv')\n\ndef tokenize(text):\n    return word_tokenize(text.lower())\n\ntrain_texts = train_df['text'].tolist()\ntrain_labels = train_df['label'].tolist()\n\nval_texts = val_df['text'].tolist()\nval_labels = val_df['label'].tolist()\n\ntest_texts = test_df['text'].tolist()\ntest_labels = test_df['label'].tolist()\n\nlabel_encoder = LabelEncoder()\ntrain_labels = label_encoder.fit_transform(train_labels)\nval_labels = label_encoder.transform(val_labels)\ntest_labels = label_encoder.transform(test_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T16:34:20.400295Z","iopub.execute_input":"2024-12-09T16:34:20.400791Z","iopub.status.idle":"2024-12-09T16:34:20.901553Z","shell.execute_reply.started":"2024-12-09T16:34:20.400753Z","shell.execute_reply":"2024-12-09T16:34:20.900818Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"all_texts = train_texts + val_texts + test_texts\ntokenized_texts = [tokenize(text) for text in all_texts]\n\nword_counts = Counter([word for sentence in tokenized_texts for word in sentence])\nvocab = {word: idx+2 for idx, (word, _) in enumerate(word_counts.most_common())}\nvocab['<PAD>'] = 0  # Padding token\nvocab['<UNK>'] = 1  # Unknown token\n\ndef text_to_sequence(text, vocab):\n    return [vocab.get(word, vocab['<UNK>']) for word in tokenize(text)]\n\ntrain_sequences = [text_to_sequence(text, vocab) for text in train_texts]\nval_sequences = [text_to_sequence(text, vocab) for text in val_texts]\ntest_sequences = [text_to_sequence(text, vocab) for text in test_texts]\n\ndef pad_sequences(sequences, max_len=100):\n    return [seq[:max_len] + [0] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in sequences]\n\ntrain_sequences = pad_sequences(train_sequences)\nval_sequences = pad_sequences(val_sequences)\ntest_sequences = pad_sequences(test_sequences)\n\nX_train = torch.tensor(train_sequences, dtype=torch.long)\ny_train = torch.tensor(train_labels, dtype=torch.long)\nX_val = torch.tensor(val_sequences, dtype=torch.long)\ny_val = torch.tensor(val_labels, dtype=torch.long)\nX_test = torch.tensor(test_sequences, dtype=torch.long)\ny_test = torch.tensor(test_labels, dtype=torch.long)\n\n\nbatch_size = 16\ntrain_data = TensorDataset(X_train, y_train)\nval_data = TensorDataset(X_val, y_val)\ntest_data = TensorDataset(X_test, y_test)\n\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=batch_size)\ntest_loader = DataLoader(test_data, batch_size=batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T16:34:20.903757Z","iopub.execute_input":"2024-12-09T16:34:20.904159Z","iopub.status.idle":"2024-12-09T16:34:44.876054Z","shell.execute_reply.started":"2024-12-09T16:34:20.904118Z","shell.execute_reply":"2024-12-09T16:34:44.875243Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class BiLSTMModel(nn.Module):\n    def __init__(self, vocab_size, embed_size=100, hidden_size=128, num_classes=2):\n        super(BiLSTMModel, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        self.bilstm = nn.LSTM(embed_size, hidden_size, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden_size * 2, num_classes)  \n        \n    def forward(self, x):\n        x = self.embedding(x)  \n        lstm_out, (hn, cn) = self.bilstm(x)  \n        hidden_state = torch.cat((hn[0], hn[1]), dim=1)  \n        out = self.fc(hidden_state)  \n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T16:34:44.877285Z","iopub.execute_input":"2024-12-09T16:34:44.877644Z","iopub.status.idle":"2024-12-09T16:34:44.884450Z","shell.execute_reply.started":"2024-12-09T16:34:44.877603Z","shell.execute_reply":"2024-12-09T16:34:44.883354Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"vocab_size = len(vocab)\nmodel = BiLSTMModel(vocab_size)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T16:34:44.885550Z","iopub.execute_input":"2024-12-09T16:34:44.885891Z","iopub.status.idle":"2024-12-09T16:34:46.246241Z","shell.execute_reply.started":"2024-12-09T16:34:44.885847Z","shell.execute_reply":"2024-12-09T16:34:46.245505Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def train(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n    best_val_acc = 0.0\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0.0\n        correct = 0\n        total = 0\n        for texts, labels in train_loader:\n            texts, labels = texts.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(texts)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n\n        train_acc = correct / total\n        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}, Train Accuracy: {train_acc:.4f}\")\n\n        model.eval()\n        val_correct = 0\n        val_total = 0\n        with torch.no_grad():\n            for texts, labels in val_loader:\n                texts, labels = texts.to(device), labels.to(device)\n                outputs = model(texts)\n                _, predicted = torch.max(outputs, 1)\n                val_correct += (predicted == labels).sum().item()\n                val_total += labels.size(0)\n\n        val_acc = val_correct / val_total\n        print(f\"Validation Accuracy: {val_acc:.4f}\")\n\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), '/kaggle/working/best_model.pth')\n\ntrain(model, train_loader, val_loader, criterion, optimizer, epochs=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T16:34:46.247361Z","iopub.execute_input":"2024-12-09T16:34:46.247873Z","iopub.status.idle":"2024-12-09T16:37:02.456455Z","shell.execute_reply.started":"2024-12-09T16:34:46.247835Z","shell.execute_reply":"2024-12-09T16:37:02.455509Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 0.3673, Train Accuracy: 0.8547\nValidation Accuracy: 0.8689\nEpoch 2, Loss: 0.2689, Train Accuracy: 0.8946\nValidation Accuracy: 0.8873\nEpoch 3, Loss: 0.2149, Train Accuracy: 0.9176\nValidation Accuracy: 0.8888\nEpoch 4, Loss: 0.1621, Train Accuracy: 0.9376\nValidation Accuracy: 0.8910\nEpoch 5, Loss: 0.1027, Train Accuracy: 0.9620\nValidation Accuracy: 0.8802\nEpoch 6, Loss: 0.0566, Train Accuracy: 0.9803\nValidation Accuracy: 0.8789\nEpoch 7, Loss: 0.0305, Train Accuracy: 0.9898\nValidation Accuracy: 0.8805\nEpoch 8, Loss: 0.0175, Train Accuracy: 0.9945\nValidation Accuracy: 0.8846\nEpoch 9, Loss: 0.0157, Train Accuracy: 0.9956\nValidation Accuracy: 0.8767\nEpoch 10, Loss: 0.0137, Train Accuracy: 0.9957\nValidation Accuracy: 0.8816\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"model.load_state_dict(torch.load('/kaggle/working/best_model.pth'))\nmodel.eval()\n\ntest_correct = 0\ntest_total = 0\nwith torch.no_grad():\n    for texts, labels in test_loader:\n        texts, labels = texts.to(device), labels.to(device)\n        outputs = model(texts)\n        _, predicted = torch.max(outputs, 1)\n        test_correct += (predicted == labels).sum().item()\n        test_total += labels.size(0)\n\ntest_acc = test_correct / test_total\nprint(f\"Test Accuracy: {test_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T16:37:06.756340Z","iopub.execute_input":"2024-12-09T16:37:06.757298Z","iopub.status.idle":"2024-12-09T16:37:07.492023Z","shell.execute_reply.started":"2024-12-09T16:37:06.757249Z","shell.execute_reply":"2024-12-09T16:37:07.491127Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_23/4090208520.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('/kaggle/working/best_model.pth'))\n","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 0.9267\n","output_type":"stream"}],"execution_count":8}]}