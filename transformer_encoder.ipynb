{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-07T17:32:19.842230Z",
     "iopub.status.busy": "2024-12-07T17:32:19.840781Z",
     "iopub.status.idle": "2024-12-07T17:32:49.452577Z",
     "shell.execute_reply": "2024-12-07T17:32:49.451725Z",
     "shell.execute_reply.started": "2024-12-07T17:32:19.842168Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install wandb -qU\n",
    "\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T04:05:59.834679Z",
     "iopub.status.busy": "2024-12-12T04:05:59.834392Z",
     "iopub.status.idle": "2024-12-12T04:06:04.507991Z",
     "shell.execute_reply": "2024-12-12T04:06:04.506951Z",
     "shell.execute_reply.started": "2024-12-12T04:05:59.834650Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# print(f\"Using {device} device\")\n",
    "\n",
    "# train_data = pd.read_csv(\"/kaggle/input/vietnamesesentimentanalytics/train.csv\")\n",
    "# test_data = pd.read_csv(\"/kaggle/input/vietnamesesentimentanalytics/test.csv\")\n",
    "\n",
    "# train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T04:06:04.510025Z",
     "iopub.status.busy": "2024-12-12T04:06:04.509703Z",
     "iopub.status.idle": "2024-12-12T04:06:04.647756Z",
     "shell.execute_reply": "2024-12-12T04:06:04.646577Z",
     "shell.execute_reply.started": "2024-12-12T04:06:04.509997Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          b·∫•p b√™nh vl th·∫ø\n",
       "1        th·∫•y ch√°n ad page n√†y ki·∫øn th·ª©c th√¨ n√¥ng c·∫£n c...\n",
       "2             giang giang ƒë·ªó th·ªã ng·ªçc h√† trend m·ªõi k√¨a k√¨a\n",
       "3        ƒëcm üòí sau c√≥ con cho h√∫t c·ªè ch·ªØa b·ªánh ch·ª© ƒë√©o ...\n",
       "4                                       m√° n·ª©ng qu√° aiu ∆°i\n",
       "                               ...                        \n",
       "47949                                 th√™m ch√∫t 17+ ƒëi fen\n",
       "47950    ƒë∆°n gi·∫£n btc n√≥ gi·ªëng nh∆∞ 1 c√°i m√°y slot c·ªù b·∫°...\n",
       "47951    vƒÉn v·∫ª ƒë·ªçc lo·∫°n c·∫£ n√£o ch·ªß th·ªõt cho n√≥ de ƒëi,9...\n",
       "47952          c√≥ loz ti·ªÅn m√† ƒë·∫ßu t∆∞ ƒë∆∞·ª£c h·∫øt c√°c ƒëi·ªÉm thi\n",
       "47953    ƒëm th·∫•t b·∫°i vcl. 4 m·∫π con t·ª± nhi√™n ch·∫øt oan v√¨...\n",
       "Name: text, Length: 47954, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_data(text):\n",
    "    text = text.lower().strip()\n",
    "    return text\n",
    "\n",
    "train_data['text'] = train_data['text'].apply(preprocess_data)\n",
    "test_data['text'] = test_data['text'].apply(preprocess_data)\n",
    "train_data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T04:06:04.649559Z",
     "iopub.status.busy": "2024-12-12T04:06:04.649192Z",
     "iopub.status.idle": "2024-12-12T04:06:05.235553Z",
     "shell.execute_reply": "2024-12-12T04:06:05.234577Z",
     "shell.execute_reply.started": "2024-12-12T04:06:04.649526Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53834"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_vocab(texts):\n",
    "    tokenizer = lambda x: x.split()\n",
    "    tokens = [tokenizer(text) for text in texts]\n",
    "    vocab = {word: idx + 2 for idx, word in enumerate(set(word for text in tokens for word in text))}\n",
    "    vocab['<pad>'] = 0\n",
    "    vocab['<unk>'] = 1\n",
    "    return vocab\n",
    "\n",
    "vocab = build_vocab(train_data['text'])\n",
    "test_vocab = build_vocab(test_data['text'])\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T04:06:05.237925Z",
     "iopub.status.busy": "2024-12-12T04:06:05.237608Z",
     "iopub.status.idle": "2024-12-12T04:06:12.283009Z",
     "shell.execute_reply": "2024-12-12T04:06:12.281949Z",
     "shell.execute_reply.started": "2024-12-12T04:06:05.237895Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def text_to_sequence(text, vocab, max_len=512):\n",
    "    words = text.split()\n",
    "    sequence = [vocab.get(word, vocab['<unk>']) for word in words]\n",
    "    if len(sequence) >= max_len:\n",
    "        sequence = sequence[:max_len]\n",
    "    else:\n",
    "        sequence.extend([vocab['<pad>']] * (max_len - len(sequence)))\n",
    "    return sequence\n",
    "\n",
    "def process_data(dataset, vocab, max_len=512):\n",
    "    labels = dataset[\"label\"]\n",
    "    texts = [text_to_sequence(text, vocab, max_len) for text in dataset[\"text\"]]\n",
    "    return torch.tensor(texts), torch.tensor(labels)\n",
    "\n",
    "train_texts, train_labels = process_data(train_data, vocab)\n",
    "test_texts, test_labels = process_data(test_data, vocab)\n",
    "\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(train_texts, train_labels)\n",
    "test_dataset = TensorDataset(test_texts, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T04:06:12.284916Z",
     "iopub.status.busy": "2024-12-12T04:06:12.284544Z",
     "iopub.status.idle": "2024-12-12T04:06:12.319795Z",
     "shell.execute_reply": "2024-12-12T04:06:12.318631Z",
     "shell.execute_reply.started": "2024-12-12T04:06:12.284887Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class InputEmbedding(nn.Module):\n",
    "    def __init__(self, d_model: int, vocab_size: int):\n",
    "        super(InputEmbedding, self).__init__()\n",
    "        self.d_model = torch.tensor(d_model)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x) * torch.sqrt(self.d_model)\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model: int, seq_len: int, dropout: float):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        eq = torch.zeros(seq_len, d_model) # matrix of shape (seq_len, d_model)\n",
    "\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1) # (seq_len, 1)\n",
    "\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "\n",
    "        eq[:, 0::2] = torch.sin(position * div_term)\n",
    "        eq[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        eq = eq.unsqueeze(0)\n",
    "        self.register_buffer('eq', eq)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + (self.eq[:, :x.shape[1], :]).requires_grad_(False)\n",
    "        return self.dropout(x)\n",
    "\n",
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self, features: int, eps: float = 10**-6):\n",
    "        super(LayerNormalization, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.alpha = nn.Parameter(torch.ones(features)) # Multipled\n",
    "        self.bias = nn.Parameter(torch.zeros(features)) # Added\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        std = x.std(dim=-1, keepdim=True)\n",
    "        return self.alpha * (x - mean) / (std + self.eps) + self.bias\n",
    "\n",
    "class FeedForwardBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, d_ff: int, dropout: float):\n",
    "        super(FeedForwardBlock, self).__init__()\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff) # W1 and b1\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model) # W2 and b2\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (Batch, Seq_len, d_model) -> (Batch, Seq_len, d_ff) -> (Batch, Seq_len, d_model)\n",
    "        return self.linear_2(self.dropout(torch.relu(self.linear_1(x))))\n",
    "\n",
    "class MultiHeadAttentionBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, h: int, dropout: float):\n",
    "        super(MultiHeadAttentionBlock, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.h = h\n",
    "        assert d_model % h == 0, \"d_model is not divided by h\"\n",
    "\n",
    "        self.d_k = d_model // h\n",
    "        self.W_Q = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_K = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_V = nn.Linear(d_model, d_model, bias=False)\n",
    "\n",
    "        self.W_O = nn.Linear(h * self.d_k, d_model, bias=False)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    @staticmethod\n",
    "    def attention(query, key, value, mask, dropout: nn.Dropout):\n",
    "        d_k = query.shape[-1]\n",
    "\n",
    "        # (Batch, h, Seq_len, d_k) --> (Batch, h, Seq_len, Seq_len)\n",
    "        attention_scores = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        if mask is not None:\n",
    "            attention_scores.masked_fill_(mask == 0, -1e9)\n",
    "\n",
    "        attenttion_scores = attention_scores.softmax(dim = -1) # (Batch, h, Seq_len, Seq_len)\n",
    "\n",
    "        if dropout is not None:\n",
    "            attention_scores = dropout(attention_scores)\n",
    "\n",
    "        return (attention_scores @ value), attention_scores\n",
    "\n",
    "    def forward(self, Q, K, V, mask):\n",
    "        query = self.W_Q(Q) # (Batch, Seq_len, d_model) --> (Batch, Seq_len, d_model)\n",
    "        key = self.W_K(K)\n",
    "        value = self.W_V(V)\n",
    "\n",
    "        # (Batch, Seq_len, d_model) --> (Batch, Seq_len, h, d_k) --> (Batch, h, Seq_len, d_k)\n",
    "        query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1, 2)\n",
    "        key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1, 2)\n",
    "        value = value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1, 2)\n",
    "\n",
    "        x, self.attention_scores = MultiHeadAttentionBlock.attention(query, key, value, mask, self.dropout)\n",
    "\n",
    "        # (Batch, h, Seq_len, d_k) --> (Batch, Seq_len, h, d_k) --> (Batch, Seq_len, d_model)\n",
    "        x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n",
    "\n",
    "        # (Batch, Seq_len, d_model) --> (Batch, Seq_len, d_model)\n",
    "        return self.W_O(x)\n",
    "\n",
    "class ResidualConnection(nn.Module):\n",
    "    def __init__(self, features: int, dropout: float):\n",
    "        super(ResidualConnection, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm = LayerNormalization(features)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, features: int, self_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForwardBlock, dropout: float):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.self_attention_block = self_attention_block\n",
    "        self.feed_forward_block = feed_forward_block\n",
    "        self.residual_connections = nn.ModuleList([ResidualConnection(features, dropout) for _ in range(2)])\n",
    "\n",
    "    def forward(self, x, src_mask):\n",
    "        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, src_mask))\n",
    "        x = self.residual_connections[1](x, self.feed_forward_block)\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, features: int, layers: nn.ModuleList):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = layers\n",
    "        self.norm = LayerNormalization(features)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size: int, d_model: int, num_classes: int, seq_len: int, N: int, h: int, d_ff: int, dropout: float = 0.1):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.input_embedding = InputEmbedding(d_model, vocab_size)\n",
    "        self.positional_embedding = PositionalEmbedding(d_model, seq_len, dropout)\n",
    "\n",
    "        encoder_blocks = []\n",
    "        for _ in range(N):\n",
    "            encoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
    "            feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\n",
    "            encoder_block = EncoderBlock(d_model, encoder_self_attention_block, feed_forward_block, dropout)\n",
    "            encoder_blocks.append(encoder_block)\n",
    "\n",
    "        self.encoder = Encoder(d_model, nn.ModuleList(encoder_blocks))\n",
    "\n",
    "        self.classification_layer = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        x = self.input_embedding(x)\n",
    "        x = self.positional_embedding(x)\n",
    "        output = self.encoder(x, mask)\n",
    "        output = output.mean(dim=1)\n",
    "        return self.classification_layer(output)\n",
    "\n",
    "def build_transformer_encoder(vocab_size, d_model, num_classes, seq_len, N, h, d_ff, dropout):\n",
    "    model = TransformerEncoder(vocab_size, d_model, num_classes, seq_len, N, h, d_ff, dropout)\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [InputEmbedding: 1, Embedding: 2, PositionalEmbedding: 1, Dropout: 2, EncoderBlock: 3, ResidualConnection: 5, LayerNormalization: 6, MultiHeadAttentionBlock: 4, Linear: 5, Linear: 5, Linear: 5, Dropout: 5, Linear: 5, Dropout: 6, ResidualConnection: 5, LayerNormalization: 6, FeedForwardBlock: 4, Linear: 5, Dropout: 5, Linear: 5, Dropout: 6, LayerNormalization: 6, Linear: 5, Linear: 5, Linear: 5]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\env\\Lib\\site-packages\\torchinfo\\torchinfo.py:295\u001b[0m, in \u001b[0;36mforward_pass\u001b[1;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m--> 295\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1582\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1580\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1582\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "Cell \u001b[1;32mIn[3], line 164\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m    163\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_embedding(x)\n\u001b[1;32m--> 164\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1582\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1580\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1582\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "Cell \u001b[1;32mIn[3], line 136\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 136\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1582\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1580\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1582\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "Cell \u001b[1;32mIn[3], line 124\u001b[0m, in \u001b[0;36mEncoderBlock.forward\u001b[1;34m(self, x, src_mask)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, src_mask):\n\u001b[1;32m--> 124\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresidual_connections\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attention_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresidual_connections[\u001b[38;5;241m1\u001b[39m](x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward_block)\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1582\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1580\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1582\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "Cell \u001b[1;32mIn[3], line 114\u001b[0m, in \u001b[0;36mResidualConnection.forward\u001b[1;34m(self, x, sublayer)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, sublayer):\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[43msublayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[3], line 124\u001b[0m, in \u001b[0;36mEncoderBlock.forward.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, src_mask):\n\u001b[1;32m--> 124\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresidual_connections[\u001b[38;5;241m0\u001b[39m](x, \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attention_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    125\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresidual_connections[\u001b[38;5;241m1\u001b[39m](x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward_block)\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1582\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1580\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1582\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "Cell \u001b[1;32mIn[3], line 99\u001b[0m, in \u001b[0;36mMultiHeadAttentionBlock.forward\u001b[1;34m(self, Q, K, V, mask)\u001b[0m\n\u001b[0;32m     97\u001b[0m value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mview(value\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], value\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_k)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 99\u001b[0m x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_scores \u001b[38;5;241m=\u001b[39m \u001b[43mMultiHeadAttentionBlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# (Batch, h, Seq_len, d_k) --> (Batch, Seq_len, h, d_k) --> (Batch, Seq_len, d_model)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 78\u001b[0m, in \u001b[0;36mMultiHeadAttentionBlock.attention\u001b[1;34m(query, key, value, mask, dropout)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# (Batch, h, Seq_len, d_k) --> (Batch, h, Seq_len, Seq_len)\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m attention_scores \u001b[38;5;241m=\u001b[39m (\u001b[43mquery\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(d_k)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 512.00 MiB. GPU ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchinfo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m build_transformer_encoder(\u001b[38;5;241m33144\u001b[39m, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m2048\u001b[39m, \u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\env\\Lib\\site-packages\\torchinfo\\torchinfo.py:223\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    216\u001b[0m validate_user_params(\n\u001b[0;32m    217\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[0;32m    218\u001b[0m )\n\u001b[0;32m    220\u001b[0m x, correct_input_size \u001b[38;5;241m=\u001b[39m process_input(\n\u001b[0;32m    221\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[0;32m    222\u001b[0m )\n\u001b[1;32m--> 223\u001b[0m summary_list \u001b[38;5;241m=\u001b[39m \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_forward_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m formatting \u001b[38;5;241m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[0;32m    227\u001b[0m results \u001b[38;5;241m=\u001b[39m ModelStatistics(\n\u001b[0;32m    228\u001b[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[0;32m    229\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\env\\Lib\\site-packages\\torchinfo\\torchinfo.py:304\u001b[0m, in \u001b[0;36mforward_pass\u001b[1;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    303\u001b[0m     executed_layers \u001b[38;5;241m=\u001b[39m [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mexecuted]\n\u001b[1;32m--> 304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [InputEmbedding: 1, Embedding: 2, PositionalEmbedding: 1, Dropout: 2, EncoderBlock: 3, ResidualConnection: 5, LayerNormalization: 6, MultiHeadAttentionBlock: 4, Linear: 5, Linear: 5, Linear: 5, Dropout: 5, Linear: 5, Dropout: 6, ResidualConnection: 5, LayerNormalization: 6, FeedForwardBlock: 4, Linear: 5, Dropout: 5, Linear: 5, Dropout: 6, LayerNormalization: 6, Linear: 5, Linear: 5, Linear: 5]"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "model = build_transformer_encoder(33144, 512, 3, 512, 6, 8, 2048, 0.1)\n",
    "print(summary(model, input_size=(64, 512), dtypes=[torch.long]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T04:06:12.324768Z",
     "iopub.status.busy": "2024-12-12T04:06:12.324446Z",
     "iopub.status.idle": "2024-12-12T04:06:12.337343Z",
     "shell.execute_reply": "2024-12-12T04:06:12.336325Z",
     "shell.execute_reply.started": "2024-12-12T04:06:12.324739Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc\n",
    "\n",
    "def train_step(model, data_loader, loss_fn, optimizer, accuracy_fn, device):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_pred = model(X).to(device)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        train_acc += accuracy_fn(y, y_pred.argmax(dim=1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_step(model, data_loader, loss_fn, accuracy_fn, device):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(data_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            test_pred = model(X).to(device)\n",
    "            loss = loss_fn(test_pred, y)\n",
    "            test_loss += loss.item()\n",
    "            test_acc += accuracy_fn(y, test_pred.argmax(dim=1))\n",
    "\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T04:28:02.210287Z",
     "iopub.status.busy": "2024-12-12T04:28:02.209861Z",
     "iopub.status.idle": "2024-12-12T04:28:02.216021Z",
     "shell.execute_reply": "2024-12-12T04:28:02.215037Z",
     "shell.execute_reply.started": "2024-12-12T04:28:02.210252Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "configs = [\n",
    "    {\"name\": \"default\", \"learning_rate\": 0.0001, \"epochs\": 10, \"seq_len\": 512, \"batch_size\": 64, \"d_model\": 512, \"N\": 6, \"h\": 8, \"dropout\": 0.1, \"d_ff\": 2048},\n",
    "    {\"name\": \"modified\", \"learning_rate\": 0.0001, \"epochs\": 10, \"seq_len\": 512, \"batch_size\": 64, \"d_model\": 256, \"N\": 3, \"h\": 8, \"dropout\": 0.1, \"d_ff\": 2048},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T17:33:00.164826Z",
     "iopub.status.busy": "2024-12-07T17:33:00.164395Z",
     "iopub.status.idle": "2024-12-07T19:52:29.794258Z",
     "shell.execute_reply": "2024-12-07T19:52:29.793454Z",
     "shell.execute_reply.started": "2024-12-07T17:33:00.164787Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mduonghieu27112004\u001b[0m (\u001b[33mduonghieu27112004-uet\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241207_173300-3oypoejm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/duonghieu27112004-uet/sentiment-analysis-transformer/runs/3oypoejm' target=\"_blank\">default</a></strong> to <a href='https://wandb.ai/duonghieu27112004-uet/sentiment-analysis-transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/duonghieu27112004-uet/sentiment-analysis-transformer' target=\"_blank\">https://wandb.ai/duonghieu27112004-uet/sentiment-analysis-transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/duonghieu27112004-uet/sentiment-analysis-transformer/runs/3oypoejm' target=\"_blank\">https://wandb.ai/duonghieu27112004-uet/sentiment-analysis-transformer/runs/3oypoejm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: default | Epoch: 1 | Train Loss: 0.4756 | Train Acc: 81.72% | Test Loss: 0.3917 | Test Acc: 81.95%\n",
      "Config: default | Epoch: 2 | Train Loss: 0.2734 | Train Acc: 89.10% | Test Loss: 0.2179 | Test Acc: 91.71%\n",
      "Config: default | Epoch: 3 | Train Loss: 0.1929 | Train Acc: 92.45% | Test Loss: 0.2259 | Test Acc: 91.57%\n",
      "Config: default | Epoch: 4 | Train Loss: 0.1451 | Train Acc: 94.47% | Test Loss: 0.2163 | Test Acc: 92.47%\n",
      "Config: default | Epoch: 5 | Train Loss: 0.1045 | Train Acc: 95.98% | Test Loss: 0.2394 | Test Acc: 92.23%\n",
      "Config: default | Epoch: 6 | Train Loss: 0.0782 | Train Acc: 97.02% | Test Loss: 0.3406 | Test Acc: 92.28%\n",
      "Config: default | Epoch: 7 | Train Loss: 0.0596 | Train Acc: 97.66% | Test Loss: 0.4027 | Test Acc: 91.98%\n",
      "Config: default | Epoch: 8 | Train Loss: 0.0471 | Train Acc: 98.10% | Test Loss: 0.4434 | Test Acc: 91.91%\n",
      "Config: default | Epoch: 9 | Train Loss: 0.0371 | Train Acc: 98.54% | Test Loss: 0.5485 | Test Acc: 91.72%\n",
      "Config: default | Epoch: 10 | Train Loss: 0.0314 | Train Acc: 98.81% | Test Loss: 0.4425 | Test Acc: 92.40%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='82.908 MB of 178.809 MB uploaded\\r'), FloatProgress(value=0.4636666341892779, max=‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà</td></tr><tr><td>test_acc</td><td>‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>test_loss</td><td>‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÜ</td></tr><tr><td>train_acc</td><td>‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train_loss</td><td>‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_acc</td><td>92.40205</td></tr><tr><td>test_loss</td><td>0.44245</td></tr><tr><td>train_acc</td><td>98.80926</td></tr><tr><td>train_loss</td><td>0.03135</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">default</strong> at: <a href='https://wandb.ai/duonghieu27112004-uet/sentiment-analysis-transformer/runs/3oypoejm' target=\"_blank\">https://wandb.ai/duonghieu27112004-uet/sentiment-analysis-transformer/runs/3oypoejm</a><br/> View project at: <a href='https://wandb.ai/duonghieu27112004-uet/sentiment-analysis-transformer' target=\"_blank\">https://wandb.ai/duonghieu27112004-uet/sentiment-analysis-transformer</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241207_173300-3oypoejm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241207_192007-zg5zrhfw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/duonghieu27112004-uet/sentiment-analysis-transformer/runs/zg5zrhfw' target=\"_blank\">modified</a></strong> to <a href='https://wandb.ai/duonghieu27112004-uet/sentiment-analysis-transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/duonghieu27112004-uet/sentiment-analysis-transformer' target=\"_blank\">https://wandb.ai/duonghieu27112004-uet/sentiment-analysis-transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/duonghieu27112004-uet/sentiment-analysis-transformer/runs/zg5zrhfw' target=\"_blank\">https://wandb.ai/duonghieu27112004-uet/sentiment-analysis-transformer/runs/zg5zrhfw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: modified | Epoch: 1 | Train Loss: 0.3949 | Train Acc: 84.38% | Test Loss: 0.2475 | Test Acc: 90.55%\n",
      "Config: modified | Epoch: 2 | Train Loss: 0.2494 | Train Acc: 90.17% | Test Loss: 0.2235 | Test Acc: 91.56%\n",
      "Config: modified | Epoch: 3 | Train Loss: 0.1980 | Train Acc: 92.34% | Test Loss: 0.2140 | Test Acc: 92.15%\n",
      "Config: modified | Epoch: 4 | Train Loss: 0.1552 | Train Acc: 94.22% | Test Loss: 0.2193 | Test Acc: 92.37%\n",
      "Config: modified | Epoch: 5 | Train Loss: 0.1241 | Train Acc: 95.44% | Test Loss: 0.2394 | Test Acc: 92.34%\n",
      "Config: modified | Epoch: 6 | Train Loss: 0.1012 | Train Acc: 96.32% | Test Loss: 0.2721 | Test Acc: 92.54%\n",
      "Config: modified | Epoch: 7 | Train Loss: 0.0826 | Train Acc: 97.03% | Test Loss: 0.2928 | Test Acc: 91.53%\n",
      "Config: modified | Epoch: 8 | Train Loss: 0.0685 | Train Acc: 97.48% | Test Loss: 0.3282 | Test Acc: 92.28%\n",
      "Config: modified | Epoch: 9 | Train Loss: 0.0588 | Train Acc: 97.90% | Test Loss: 0.3483 | Test Acc: 91.99%\n",
      "Config: modified | Epoch: 10 | Train Loss: 0.0522 | Train Acc: 98.19% | Test Loss: 0.3351 | Test Acc: 92.21%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà</td></tr><tr><td>test_acc</td><td>‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñÑ‚ñá‚ñÜ‚ñá</td></tr><tr><td>test_loss</td><td>‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá</td></tr><tr><td>train_acc</td><td>‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train_loss</td><td>‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_acc</td><td>92.21221</td></tr><tr><td>test_loss</td><td>0.33507</td></tr><tr><td>train_acc</td><td>98.18727</td></tr><tr><td>train_loss</td><td>0.05219</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">modified</strong> at: <a href='https://wandb.ai/duonghieu27112004-uet/sentiment-analysis-transformer/runs/zg5zrhfw' target=\"_blank\">https://wandb.ai/duonghieu27112004-uet/sentiment-analysis-transformer/runs/zg5zrhfw</a><br/> View project at: <a href='https://wandb.ai/duonghieu27112004-uet/sentiment-analysis-transformer' target=\"_blank\">https://wandb.ai/duonghieu27112004-uet/sentiment-analysis-transformer</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241207_192007-zg5zrhfw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for config in configs:\n",
    "    wandb.init(\n",
    "        project=\"sentiment-analysis-transformer\",\n",
    "        config=config,\n",
    "        name=config[\"name\"],\n",
    "        reinit=True\n",
    "    )\n",
    "    \n",
    "    config = wandb.config\n",
    "\n",
    "    model = build_transformer_encoder(\n",
    "        vocab_size=len(vocab),\n",
    "        d_model=config.d_model,\n",
    "        num_classes=2,\n",
    "        seq_len=config.seq_len,\n",
    "        N=config.N,\n",
    "        h=config.h,\n",
    "        d_ff=config.d_ff,\n",
    "        dropout=config.dropout,\n",
    "    ).to(device)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "    # Training Loop\n",
    "    for epoch in range(config.epochs):\n",
    "        train_loss, train_acc = train_step(model, train_loader, loss_fn, optimizer, accuracy_fn, device)\n",
    "        test_loss, test_acc = test_step(model, test_loader, loss_fn, accuracy_fn, device)\n",
    "        \n",
    "        # Log metrics to wandb\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_acc\": test_acc\n",
    "        })\n",
    "        \n",
    "        print(f\"Config: {config.name} | Epoch: {epoch+1} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "    # Save the model checkpoint for this configuration\n",
    "    model_file = f\"sentiment_transformer_{config.name}.pth\"\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    wandb.save(model_file)\n",
    "\n",
    "    # Finish the current wandb run\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T04:54:55.386254Z",
     "iopub.status.busy": "2024-12-12T04:54:55.385431Z",
     "iopub.status.idle": "2024-12-12T04:55:33.837476Z",
     "shell.execute_reply": "2024-12-12T04:55:33.836463Z",
     "shell.execute_reply.started": "2024-12-12T04:54:55.386212Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate for default model:\n",
      "Precision: 0.7726\n",
      "Recall: 0.7601\n",
      "F1 Score: 0.7662\n",
      "========================================\n",
      "Evaluate for modified model:\n",
      "Precision: 0.7660\n",
      "Recall: 0.7802\n",
      "F1 Score: 0.7729\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# metric score using confusion matrix and f1 score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def eval(model, data_loader, device):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(data_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            eval_pred = model(X).to(device)\n",
    "            eval_pred = torch.argmax(eval_pred, dim=1)\n",
    "            \n",
    "            y_true.extend(y.cpu().numpy())\n",
    "            y_pred.extend(eval_pred.cpu().numpy())\n",
    "\n",
    "    y_true = [int(label) for label in y_true]\n",
    "    y_pred = [int(label) for label in y_pred]\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "default = build_transformer_encoder(\n",
    "    vocab_size = len(vocab),\n",
    "    d_model = configs[0]['d_model'],\n",
    "    num_classes=2,\n",
    "    seq_len=configs[0]['seq_len'],\n",
    "    N=configs[0]['N'],\n",
    "    h=configs[0]['h'],\n",
    "    d_ff=configs[0]['d_ff'],\n",
    "    dropout=configs[0]['dropout']\n",
    ").to(device)\n",
    "default.load_state_dict(\n",
    "    torch.load('/kaggle/input/model-transformer/sentiment_transformer_default.pth', weights_only=True)\n",
    ")\n",
    "\n",
    "modified =  build_transformer_encoder(\n",
    "    vocab_size = len(vocab),\n",
    "    d_model = configs[1]['d_model'],\n",
    "    num_classes=2,\n",
    "    seq_len=configs[1]['seq_len'],\n",
    "    N=configs[1]['N'],\n",
    "    h=configs[1]['h'],\n",
    "    d_ff=configs[1]['d_ff'],\n",
    "    dropout=configs[1]['dropout']\n",
    ").to(device)\n",
    "modified.load_state_dict(\n",
    "    torch.load('/kaggle/input/model-transformer/sentiment_transformer_modified.pth', weights_only=True)\n",
    ")\n",
    "\n",
    "print(\"Evaluate for default model:\")\n",
    "eval(default, test_loader, 'cuda')\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(\"Evaluate for modified model:\")\n",
    "eval(modified, test_loader, 'cuda')\n",
    "print(\"=\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6252177,
     "sourceId": 10130662,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
